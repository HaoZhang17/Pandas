## 第一章重点总结

#### 一、属性与方法的使用区别
访问Series或DataFrame<u>**属性**</u>时<u>**不加括号**</u>，调取<u>**函数方法**</u>时需<u>**加括号**</u>
```
> s = pd.Series(np.random.randn(5), index = ['a', 'b', 'c', 'd', 'e'], name = 'This is a series', dtype='float64')
s

# 访问Series属性
> s.values
array([ 1.10668501, -0.81180358,  0.40747849, -0.95315818, -2.23482878])

> s.name
'This is a series'

> s.dtype
dtype('float64')

> s.index
Index(['a', 'b', 'c', 'd', 'e'], dtype='object')

# 调用Series方法
> s.value_counts()
-0.811804    1
-2.234829    1
 0.407478    1
 1.106685    1
-0.953158    1
Name: This is a series, dtype: int64

> s.mean()
-0.4971254097304076

> s.sort_values()
e   -2.234829
d   -0.953158
b   -0.811804
c    0.407478
a    1.106685
Name: This is a series, dtype: float64

> s.isnull()
a    False
b    False
c    False
d    False
e    False
Name: This is a series, dtype: bool

> s.isna()
a    False
b    False
c    False
d    False
e    False
Name: This is a series, dtype: bool
```

#### 二、DataFrame的创建
其余几种方法描述和代码后续补充于此……
```
占位
```

方法N：直接使用`to_frame`方法将Series转成DataFrame
```
> df
	col1	col2	col3
一	a	5	1.3
二	b	6	2.5
三	c	7	3.6
四	d	8	4.6
五	e	9	5.8

> s = df.mean()
> s.name='to_DataFrame'
> s
col2    7.00
col3    3.56
Name: to_DataFrame, dtype: float64

# DataFrame
> s.to_frame()
	to_DataFrame
col2	7.00
col3	3.56
```

#### 三、DataFrame列的检索

检索（选择）DataFrame的列有四种方法：

1. 根据索引选择
```
> df = pd.DataFrame({'col1':list('abcde'),'col2':range(5,10),'col3':[1.3,2.5,3.6,4.6,5.8]}, index=list('一二三四五'))
> df
	col1	col2	col3
一	a	5	1.3
二	b	6	2.5
三	c	7	3.6
四	d	8	4.6
五	e	9	5.8

> df['col1']
一    a
二    b
三    c
四    d
五    e
Name: col1, dtype: object

> df[['col1', 'col2']]
	col1	col2
一	a	5
二	b	6
三	c	7
四	d	8
五	e	9

## 注：如果为数字则索引行
> df[:2]
	col1	col2	col3
一	a	5	1.3
二	b	6	2.5
```

2. 根据属性选择
```
> df.col1
一    a
二    b
三    c
四    d
五    e
Name: col1, dtype: object
```

3. 使用特殊索引轴标签（loc）和整数标签（iloc）
```
> df.loc[:,'col1']
一    a
二    b
三    c
四    d
五    e
Name: col1, dtype: object

> df.iloc[:, 1]
一    5
二    6
三    7
四    8
五    9
Name: col2, dtype: int64
```

4. 根据类型选择列
```
# 查看数据类型
> df.info()
<class 'pandas.core.frame.DataFrame'>
Index: 5 entries, 一 to 五
Data columns (total 3 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   col1    5 non-null      object 
 1   col2    5 non-null      int64  
 2   col3    5 non-null      float64
dtypes: float64(1), int64(1), object(1)
memory usage: 320.0+ bytes

# 根据类型选择列
> df.select_dtypes(include=['number']).head()
	col2	col3
一	5	1.3
二	6	2.5
三	7	3.6
四	8	4.6
五	9	5.8
```

#### 四、DataFrame列或行的删除
删除特定列可用`drop`、`del`或`pop`，区别在于：

1. `drop`: 通过指定标签（labels）和轴向（axis）来删除<u>**行或列**</u>，可指定多行或多列，返回删除后的DataFrame

`DataFrame.drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')`

参数：
1. labels：单个标签（索引或列标签）或标签列表
2. axis：轴向，0为行方向（索引），1为列方向（列标签）
3. index：指定特定索引，axis=0时等同于labels
4. columns：指定特定列标签，axis=1时等同于labels
5. level：对于多级索引，指定哪级索引被移除
6. inplace：是否替换原DataFrame

```
> df
	col1	col2	col3
一	a	5	1.3
二	b	6	2.5
三	c	7	3.6
四	d	8	4.6
五	e	9	5.8

> df.drop(index='五',columns='col1')
	col2	col3
一	5	1.3
二	6	2.5
三	7	3.6
四	8	4.6
```


2. `del`：删除特定一列（非多列），不返回
```
> df['col1']=[1,2,3,4,5]
> del df['col1']
> df
	col2	col3
一	5	1.3
二	6	2.5
三	7	3.6
四	8	4.6
五	9	5.8

# 注意：不能删除多列，以下为错误示例
> del df['col1', 'col2']
> del df.loc[:, ['col1', 'col2']]
```

3. `pop`：删除特定列（非多列），对原DataFrame进行删除，并返回删除的列（Series）

`DataFrame.pop(self: ~FrameOrSeries, item) `

参数：
`item`：字符串，要被移除的列标签（注意不能为列表）

#### 五、DataFrame列的添加
DataFrame列的添加有两种方法：

1. 直接赋值

* 将<u>**列表或数组**</u>赋值给一列，使用该方法需注意值的长度必须和DataFrame的长度匹配，对原对象直接进行修改
```
> df1
	A
1	1
2	2
3	3

> df1['B'] = list('abc')
> df1
	A	B
1	1	a
2	2	b
3	3	c

# 注：不能使用类似df1.B的语法，以下为错误示例
> df1.B = list('abc')
```

* 将<u>**Series**</u>赋值给一列，使用该方法会<u>**按照DataFrame的索引重新排序，并在空缺的地方填充缺失值**</u>
```
> df1['B'] = pd.Series(list('abc'), index = [0, 1, 2])

> df1
	A	B
1	1	b
2	2	c
3	3	NaN
```

2. 使用`DataFrame.assign()`方法，返回新DataFrame，不修改原对象
```
> df1.assign(C = pd.Series(list('def')))
	A	B	C
1	1	b	e
2	2	c	f
3	3	NaN	NaN
```


#### 六、自动索引对齐
对包含有索引的Series进行数学操作时，操作只会对<u>**具有相同索引（即对应索引）**</u>的值进行。下面的示例中，执行`df2 - df1`操作时，实际上为`df2`与`df1`对应索引的值相减，如`df2`的第二行减`df1`的第一行，而非两DataFrames的第一行相减

```
> df1 = pd.DataFrame({'A': [1, 2, 3]}, index = [1, 2, 3])

> df2 = pd.DataFrame({'A': [1, 2, 3]}, index = [3, 1, 2])

> df1
	A
1	1
2	2
3	3

> df2
	A
3	1
1	2
2	3

> df2 - df1
	A
1	1
2	1
3	-2
```

#### 七、结合Apply和Lambda函数对多行和多列进行操作

##### Series数据
```
> df = pd.read_csv('data/table.csv')

> df['Math'].apply(lambda x:str(x) + '!').head()
0    34.0!
1    32.5!
2    87.2!
3    80.4!
4    84.8!
Name: Math, dtype: object
```

##### DataFrame数据

方法一：使用两次`lambda`函数，第一个lambda操作不同的列，第二个操作一列里的不同行

```
> df.apply(lambda x:x.apply(lambda x:str(x) + '!')).head()
	School	Class	ID	Gender	Address	Height	Weight	Math	Physics
0	S_1!	C_1!	1101!	M!	street_1!	173!	63!	34.0!	A+!
1	S_1!	C_1!	1102!	F!	street_2!	192!	73!	32.5!	B+!
2	S_1!	C_1!	1103!	M!	street_2!	186!	82!	87.2!	B+!
3	S_1!	C_1!	1104!	F!	street_2!	167!	81!	80.4!	B-!
4	S_1!	C_1!	1105!	F!	street_4!	159!	64!	84.8!	B+!
```

方法二：使用`applymap()`方法
```
format = lambda x:str(x) + '!'
df.applymap(format)
```


#### 八、数据类型
下图展示常见数据类型

![/img/1.jpeg]


#### 九、需要注意的函数或方法

1. `dir([object])`

无参数时返回现有局部域的列表名称，有参数时尝试返回包含对象的所有有效属性的列表

2. `type[object]`

返回包含对象的类型，等同于`object.__class__`

3. `.nunique()`: `DataFrame.nunique(self, axis=0, dropna=True`或`Series.nunique(self, dropna=True)`

计算DataFrame特定轴或Series的唯一观察值，默认忽略缺失值

4. `.unique()`: `Series.unique(self)`

显示Series的唯一值

5. `DataFrame.count(self, axis=0, level=None, numeric_only=False)`或`Series.count(self, level=None)`

计算DataFrame特定轴或Series的非缺失值的数目

6. `.value_counts()`, `Series.value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)`

计算Series每类元素的数目，结果以出现频次降序排列

7. `.nlargest()`: `DataFrame.nlargest(self, n, columns, keep='first')`或`Series.nlargest(self, n=5, keep='first')`

返回DataFrame特定列最大的前n行或Series最大的前n个元素

参数：

`keep`: {‘first’, ‘last’, ‘all’}，默认为‘first’
当出现重复值时：
`first`：优先返回重复值中的第一个值，丢弃其它值
`last`：优先返回重复值中的最后一个值，丢弃其它值
`all`：不丢弃任何值，即使值的总数超过了n个

```
> df = pd.DataFrame({'population': [59000000, 65000000, 434000,
...                               434000, 434000, 337000, 11300,
...                               11300, 11300],
...                 'GDP': [1937894, 2583560 , 12011, 4520, 12128,
...                         17036, 182, 38, 311],
...                 'alpha-2': ["IT", "FR", "MT", "MV", "BN",
...                             "IS", "NR", "TV", "AI"]},
...                 index=["Italy", "France", "Malta",
...                        "Maldives", "Brunei", "Iceland",
...                        "Nauru", "Tuvalu", "Anguilla"])

> df
	population	GDP	alpha-2
Italy	59000000	1937894	IT
France	65000000	2583560	FR
Malta	434000	12011	MT
Maldives	434000	4520	MV
Brunei	434000	12128	BN
Iceland	337000	17036	IS
Nauru	11300	182	NR
Tuvalu	11300	38	TV
Anguilla	11300	311	A

> df.nlargest(3, 'population', keep='last')
        population      GDP alpha-2
France    65000000  2583560      FR
Italy     59000000  1937894      IT
Brunei      434000    12128      BN

> df.nlargest(3, 'population', keep='all')
          population      GDP alpha-2
France      65000000  2583560      FR
Italy       59000000  1937894      IT
Malta         434000    12011      MT
Maldives      434000     4520      MV
Brunei        434000    12128      BN
```

8. `.clip()`: `DataFrame.clip(self: ~FrameOrSeries, lower=None, upper=None, axis=None, inplace: bool = False, *args, **kwargs)`或`Series.clip(self: ~FrameOrSeries, lower=None, upper=None, axis=None, inplace: bool = False, *args, **kwargs)`

用阈值对数据进行截断

```
> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}
> df = pd.DataFrame(data)
> df
	col_0  col_1
0      9     -2
1     -3     -7
2      0      6
3     -1      8
4      5     -5

> df.clip(-4, 6)
	col_0  col_1
0      6     -2
1     -3     -4
2      0      6
3     -1      6
4      5     -4
```

9. `.replace()`: `DataFrame.replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')`或`Series.replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')`

参数：

`to_replace`：如何找到将被替换的值，可为数字、字符串、正则表达式、列表、字典或None
`value`：对满足`to_replace`的项进行替代的值，可为数字、字符串、正则表达式、列表、字典或`None`
`inplace`：是否对原数据进行修改
`regex`：是否将`to_replace`和/或`value`解析为正则表达式，如果为真，`to_replace`必须为字符串。此参数也可为正则表达式，这时`to_replace`必须为`None`
`method`：{‘pad’, ‘ffill’, ‘bfill’, None}
用于替换的方法（`to_replace`为标量、列表或元组且`value`为None）

```
> s = pd.Series([0, 1, 2, 3, 4])

> s
0    0
1    1
2    2
3    3
4    4
dtype: int64

> s.replace(0, 5)
0    5
1    1
2    2
3    3
4    4
dtype: int64

# 将1和2用后一个数值3向前填充
> s.replace(to_replace=[1, 2], method='bfill')
0    0
1    3
2    3
3    3
4    4
dtype: int64
```


* * *

#### 十、“问题与练习”部分

> 注：本部分问题来自Datawhale《Pandas教程》第一章

### 1. 问题

##### 【问题一】 Series和DataFrame有哪些常见属性和方法？

答：
1. Series和DataFrame常见属性：values, index, name, index.name, dtypes, columns(DataFrame)...
2. Series和DataFrame常见方法：
* 常规方法：isnull(), isna(), notnull(), notna(), dropna(), fillna(), map(), replace(), rename(), head(), tail(), loc(), iloc(), reindex(), drop(), apply(), applymap(), is_unique(Series), unique(Series), nunique(Series), drop_duplicates(), set_index(), reset_index(), sort_index(), sort_values(), rank(), describe(), isin(), match(), read_table(), read_csv(), read_excel(), read_json(), to_csv()...
* 算术方法：add(), sub(), div(), 整除floordiv(), mul(), 幂次方pow(), sum(), mean(), median(), min(), max(), argmin(), argmax(), idxmin(), idxmax(), quantile(), mad(), prod(), var(), std(), cumsum(), cummin(), cummax(), cumprod(), diff(), pct_change(), skew() ,kurt(), count(), value_counts(), cov(), corr(),  corrwith()...

##### 【问题二】 value_counts会统计缺失值吗？

答：依具体参数而定，value_counts在统计数据时，参数`dropna`默认为真，即不统计缺失值。

##### 【问题三】 与idxmax和nlargest功能相反的是哪两组函数？

答：与idxmax和nlargest功能相反的函数分别为idmin和nsmallest。

##### 【问题四】 在常用函数一节中，由于一些函数的功能比较简单，因此没有列入，现在将它们列在下面，请分别说明它们的用途并尝试使用。sum/mean/median/mad/min/max/abs/std/var/quantile/cummax/cumsum/cumprod

答：这些都是算术函数

| 函数名 | 用途 |
| --- | --- |
| sum | 加和 |
| mean | 均值 |
| median | 中位数 |
| mad | 均值的平均绝对偏差 |
| min | 最小值 |
| max | 最大值 |
| abs | 绝对值 |
| std | 标准差 |
| var | 样本方差 |
| quantile | 计算分位数 |
| cumsum | 累计值 |
| cummax | 累计值的最大值 |
| cumprod | 累计积 |
| pct_change | 计算百分比 |

##### 【问题五】 df.mean(axis=1)是什么意思？它与df.mean()的结果一样吗？第一问提到的函数也有axis参数吗？怎么使用？

答：对df所有行计算均值。与df.mean()不同，后者默认对所有列计算。当axis设为0或"rows"时，表示在行的方向上即对所有列计算；当axis设为1或"columns"时，表示在列的方向上即对所有行计算。

#### 2. 练习
##### 【练习一】 现有一份关于美剧《权力的游戏》剧本的数据集，请解决以下问题：
##### （a）在所有的数据中，一共出现了多少人物？

答：共出现了564个人物，代码如下：
```
> df = pd.read_csv('data/Game_of_Thrones_Script.csv')
> df['Name'].nunique()
564
```

##### （b）以单元格计数（即简单把一个单元格视作一句），谁说了最多的话？

答：以单元格计数，Tyrion Lannister说了最多的话，共1760句，代码如下：
```
> df['Name'].value_counts()
tyrion lannister      1760
jon snow              1133
daenerys targaryen    1048
cersei lannister      1005
jaime lannister        945
                      ... 
both                     1
unsullied captain        1
client                   1
ser rodrik               1
timett                   1
Name: Name, Length: 564, dtype: int64
```

##### （c）以单词计数，谁说了最多的单词？

思路：分割每一句话，统计每一句的单词数。因为每个断句标点后都有一个空格，因此直接句子以空格进行分割。随后对相同的人每一句的单词数进行加和后排序。
注：将单词缩写连同前一个单词默认为一个单词。

答：以单词计数，Tyrion Lannister说了最多的单词，共26009个，代码如下：
```
# 统计每一句的单词数
## 方法一：直接用字符串方法
> df['Sentence_word_count'] =  df['Sentence'].str.strip().str.split().str.len()

## 方法二：用lambda+apply方法
> df['Sentence_word_count'] = df['Sentence'].apply(lambda x:len(x.strip().split()))

# 对相同的人每一句的单词数进行加和后排序
> df['Sentence_word_count'].groupby(df['Name']).sum().sort_values(ascending = False)
Name
tyrion lannister      26009
cersei lannister      14442
daenerys targaryen    12358
jon snow              12298
jaime lannister       11735
                      ...  
head prostitute           1
ironborn lord             1
title                     1
main                      1
nights watchmen           1
Name: Sentence_word_count, Length: 564, dtype: int64
```

#### 【练习二】现有一份关于科比的投篮数据集，请解决如下问题：
##### （a）哪种action_type和combined_shot_type的组合是最多的？

答：最多的action_type和combined_shot_type的组合为Jump Shot+Jump Shot组合，共18880次，代码如下：
```
> df = pd.read_csv('data/Kobe_data.csv',index_col='shot_id')

# 方法一：用str方法将两组字符串拼接为一组，然后计数和排序
> df['action_type'].str.cat(df['combined_shot_type'], sep = ' + ').value_counts().head()
Jump Shot + Jump Shot               18880
Layup Shot + Layup                   2567
Driving Layup Shot + Layup           1978
Turnaround Jump Shot + Jump Shot     1057
Fadeaway Jump Shot + Jump Shot       1048
Name: action_type, dtype: int64

# 方法二：使用两个键('action_type'和'combined_shot_type')同时用groupby进行分组，然后计算信息，最后计数和排序
> df.groupby(['action_type', 'combined_shot_type']).size().sort_values(ascending = False).head()
action_type           combined_shot_type
Jump Shot             Jump Shot             18880
Layup Shot            Layup                  2567
Driving Layup Shot    Layup                  1978
Turnaround Jump Shot  Jump Shot              1057
Fadeaway Jump Shot    Jump Shot              1048
dtype: int64
```

##### （b）在所有被记录的game_id中，遭遇到最多的opponent是一个支？

答：在所有被记录的game_id中，遭遇到最多的opponent是SAS，共91次，代码如下：
```
# 方法一：提取'game_id'和'opponent'列，去重后计数和排序
> deduplicate = df[['game_id', 'opponent']].drop_duplicates()
> deduplicate['opponent'].value_counts(ascending = False).head()
SAS    91
PHX    87
UTA    84
DEN    83
POR    81
Name: opponent, dtype: int64

# 方法二：使用两个键('game_id'和'opponent')同时用groupby进行分组，然后计算信息，最后计数和排序
> id_i_oppo = df.groupby(['game_id', 'opponent'],  as_index=False).count()
> id_i_oppo['opponent'].value_counts(ascending = False).head()
SAS    91
PHX    87
UTA    84
DEN    83
POR    81
Name: opponent, dtype: int64
```

* * *

#### 十一、参考资料和数据来源
##### 参考资料
1. [Pandas官方文档（v3.8）](https://docs.python.org/3.8)
2. 《利用Python进行数据分析》第二版，Wes McKinney，机械工业出版社，2018年
3. [Pandas教程，Datawhale](https://github.com/datawhalechina/joyful-pandas/blob/master/%E7%AC%AC1%E7%AB%A0%20Pandas%E5%9F%BA%E7%A1%80.ipynb)

#### 数据来源
本总结中部分数据和练习题的数据来源
[Pandas教程，Datawhale](https://github.com/datawhalechina/joyful-pandas)
