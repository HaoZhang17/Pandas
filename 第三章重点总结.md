# 第三章 分组

## 一、重难点总结

数据（按School分组后的每组前五行）

|  ID  | School | Class | Gender |  Address | Height | Weight | Math | Physics |
| ---: | -----: | ----: | -----: | -------: | -----: | -----: | ---: | ------: |
| 1101 |    S_1 |   C_1 |      M | street_1 |    173 |     63 | 34.0 |      A+ |
| 1102 |    S_1 |   C_1 |      F | street_2 |    192 |     73 | 32.5 |      B+ |
| 1103 |    S_1 |   C_1 |      M | street_2 |    186 |     82 | 87.2 |      B+ |
| 1104 |    S_1 |   C_1 |      F | street_2 |    167 |     81 | 80.4 |      B- |
| 1105 |    S_1 |   C_1 |      F | street_4 |    159 |     64 | 84.8 |      B+ |
| 2101 |    S_2 |   C_1 |      M | street_7 |    174 |     84 | 83.3 |       C |
| 2102 |    S_2 |   C_1 |      F | street_6 |    161 |     61 | 50.6 |      B+ |
| 2103 |    S_2 |   C_1 |      M | street_4 |    157 |     61 | 52.5 |      B- |
| 2104 |    S_2 |   C_1 |      F | street_5 |    159 |     97 | 72.2 |      B+ |
| 2105 |    S_2 |   C_1 |      M | street_4 |    170 |     81 | 34.2 |       A |

### 1. groupby分组键（依据）

1. 已有的DataFrame列名

```python
> df.groupby('School').head(2)
	School	Class	Gender	Address	Height	Weight	Math	Physics
ID								
1101	S_1	C_1	M	street_1	173	63	34.0	A+
1102	S_1	C_1	F	street_2	192	73	32.5	B+
2101	S_2	C_1	M	street_7	174	84	83.3	C
2102	S_2	C_1	F	street_6	161	61	50.6	B+

> df.groupby(['School','Class']).get_group(('S_2','C_4'))
	School	Class	Gender	Address	Height	Weight	Math	Physics
ID								
2401	S_2	C_4	F	street_2	192	62	45.3	A
2402	S_2	C_4	M	street_7	166	82	48.7	B
2403	S_2	C_4	F	street_6	158	60	59.7	B+
2404	S_2	C_4	F	street_2	160	84	67.7	B
2405	S_2	C_4	F	street_6	193	54	47.6	B
```

   **注意：若输入为非原列表的列，输出的分组里不会显示新的分组依据**

2. 与需分组轴向长度一致的值列表或数组

```python
# 用新生成的与数据框长度相等的一维数据进行分组
> np.random.choice(['a','b','c'], df.shape[0])
> df.groupby(np.random.choice(['a','b','c'], df.shape[0])).get_group('a').head()
	School	Class	Gender	Address	Height	Weight	Math	Physics
ID								
1101	S_1	C_1	M	street_1	173	63	34.0	A+
1102	S_1	C_1	F	street_2	192	73	32.5	B+
1205	S_1	C_2	F	street_6	167	63	68.4	B-
1301	S_1	C_3	M	street_4	161	68	31.5	B+
1302	S_1	C_3	F	street_1	175	57	87.7	A-

> grouped_abc = df.groupby(np.random.choice(['a','b','c'], df.shape[0]))
> for name, group in grouped_abc:
print(name)
print(group.head())
a
	School Class Gender   Address  Height  Weight  Math Physics
ID                                                              
1103    S_1   C_1      M  street_2     186      82  87.2      B+
1201    S_1   C_2      M  street_5     188      68  97.0      A-
2103    S_2   C_1      M  street_4     157      61  52.5      B-
2104    S_2   C_1      F  street_5     159      97  72.2      B+
2105    S_2   C_1      M  street_4     170      81  34.2       A
b
	School Class Gender   Address  Height  Weight  Math Physics
ID                                                              
1104    S_1   C_1      F  street_2     167      81  80.4      B-
1105    S_1   C_1      F  street_4     159      64  84.8      B+
1202    S_1   C_2      F  street_4     176      94  63.5      B-
1304    S_1   C_3      M  street_2     195      70  85.2       A
2101    S_2   C_1      M  street_7     174      84  83.3       C
c
	School Class Gender   Address  Height  Weight  Math Physics
ID                                                              
1101    S_1   C_1      M  street_1     173      63  34.0      A+
1102    S_1   C_1      F  street_2     192      73  32.5      B+
1203    S_1   C_2      M  street_6     160      53  58.8      A+
1204    S_1   C_2      F  street_5     162      63  33.8       B
1205    S_1   C_2      F  street_6     167      63  68.4      B-
```

3. 多层索引的层级

```python
> df.set_index(['Gender','School']).groupby(level=1, axis=0).get_group('S_1').head()
		Class	Address	Height	Weight	Math	Physics
Gender	School						
M	S_1	C_1	street_1	173	63	34.0	A+
F	S_1	C_1	street_2	192	73	32.5	B+
M	S_1	C_1	street_2	186	82	87.2	B+
F	S_1	C_1	street_2	167	81	80.4	B-
S_1	C_1	street_4	159	64	84.8	B+
```

4. 分组轴向的索引值（字典的键/Series的索引值）与分组名称（字典/Series的值）相匹配的字典或Series

```python
> mapping = {'School': 'A', 'Class': 'A', 'Gender': 'A', 'Address': 'A', 'Height': 'B', 'Weight': 'B', 'Math': 'B', 'Physics': 'A'}
> pd.Series(mapping)
School     A
Class      A
Gender     A
Address    A
Height     B
Weight     B
Math       B
Physics    A
dtype: object

> df.groupby(mapping, axis = 1).count().head()
	A	B
ID		
1101	5	3
1102	5	3
1103	5	3
1104	5	3
1105	5	3
```

5. 可在索引上调用的函数

此时传入对象实际为索引

```python
> df[:5].groupby(lambda x:print(x)).head(0)
1101
1102
1103
1104
1105

> grouped = df.groupby(lambda x:'奇数行' if not df.index.get_loc(x)%2==1 else '偶数行')
> for name,group in grouped:
print(name)
display(group.head())
偶数行
	School	Class	Gender	Address	Height	Weight	Math	Physics
ID								
1102	S_1	C_1	F	street_2	192	73	32.5	B+
1104	S_1	C_1	F	street_2	167	81	80.4	B-
1201	S_1	C_2	M	street_5	188	68	97.0	A-
1203	S_1	C_2	M	street_6	160	53	58.8	A+
1205	S_1	C_2	F	street_6	167	63	68.4	B-
奇数行
	School	Class	Gender	Address	Height	Weight	Math	Physics
ID								
1101	S_1	C_1	M	street_1	173	63	34.0	A+
1103	S_1	C_1	M	street_2	186	82	87.2	B+
1105	S_1	C_1	F	street_4	159	64	84.8	B+
1202	S_1	C_2	F	street_4	176	94	63.5	B-
1204	S_1	C_2	F	street_5	162	63	33.8	B
```


### 2. groupby对象的常用方法与函数 

| 方法或函数                            | 注释                   |
| ------------------------------------- | ---------------------- |
| `grouped_object.get_group(group key)` | 取出特定分组的内容     |
| `grouped_object.head(n)`              | 返回每组的前n行        |
| `grouped_object.size()`               | 组容量（每组的行数）   |
| `grouped_object.count()`              | 分组中非NA的数量       |
| `grouped_object.ngroups`              | 分组数（包括多层索引） |
| `grouped_object.agg()`                | 聚合函数               |
|                                       |                        |


### 3. groupby对象的应用

| 方式                         | 解释                                                         | 用法                                                         | 举例                                                         |
| ---------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| `grouped_object.agg()`       | 聚合多个函数，一般对分组进行统计，如计算分组中某项的最大、最小、极差等标量值 | 同时使用多个聚合函数                                         | `group_m.agg(['sum','mean','std'])`                          |
|                              |                                                              | 利用元组重命名                                               | `group_m.agg([('rename_sum','sum'),('rename_mean','mean')])` |
|                              |                                                              | 指定函数的作用范围（<u>**对特定列运用**</u>）                | `grouped_mul.agg({'Math':['mean','max'],'Height':'var'})`    |
|                              |                                                              | 自定义函数                                                   | `grouped_single['Math'].agg(lambda x:x.max()-x.min())`       |
|                              |                                                              | 利用`NamedAgg`函数进行多个聚合                               | 补充说明1，补充代码1                                         |
|                              |                                                              | 带参数的聚合函数                                             | 补充代码2                                                    |
| `grouped_object.filter()`    | 筛选分组                                                     | 传入lambda函数（传入的值应当是布尔标量，且每个分组一个布尔值） | 补充代码3                                                    |
| `grouped_object.transform()` | 变换输出，一般可用于组内标准化、缺失值填充或对标量值进行广播 | 传入对象为组内的列，且**返回值与列长完全一致**               | 补充代码4                                                    |
| `grouped_object.apply()`     | 可进行灵活处理与输出，即可输出标量、列表和数据框，可同时进行多个指标的统计 | 传入`lambda`函数，返回标量                                   | `df[['School','Math','Height']].groupby('School').apply(lambda x:x.max())` |
|                              |                                                              | 传入`lambda`函数，返回列表                                   | `df[['School','Math','Height']].groupby('School').apply(lambda x:x-x.min()).head()` |
|                              |                                                              | 传入`lambda`函数，返回数据框（**<u>对特定列运用</u>**）      | `df[['School','Math','Height']].groupby('School').apply(lambda x:pd.DataFrame({'col1':x['Math']-x['Math'].max(),<br/>                                  'col2':x['Math']-x['Math'].min(),<br/>                                  'col3':x['Height']-x['Height'].max(),<br/>                                  'col4':x['Height']-x['Height'].min()})).head()` |
|                              |                                                              | 借助OrderedDict工具进行快捷统计（**<u>对特定列运用</u>**）   | 补充代码5                                                    |


补充说明1：

Named aggregation

New in version 0.25.0.

To support column-specific aggregation with control over the output column names, pandas accepts the special syntax in `GroupBy.agg()`, known as “named aggregation”, where

* The keywords are the output column names.
* The values are tuples whose `first element is the column to select` and the second element is the aggregation to apply to that column. Pandas provides the `pandas.NamedAgg` namedtuple with the fields `['column', 'aggfunc']` to make it clearer what the arguments are. As usual, the aggregation can be a callable or a string alias.

注意：不支持`lambda`函数，但可使用外置的`def`函数。


```python
# 补充代码1
> def R1(x):
    return x.max()-x.min()
> def R2(x):
    return x.max()-x.median()
> grouped_single['Math'].agg(min_score1=pd.NamedAgg(column='ad libitum', aggfunc=R1),
                           max_score1=pd.NamedAgg(column='col2', aggfunc='max'),
                           range_score2=pd.NamedAgg(column='col3', aggfunc=R2)).head()
	min_score1	max_score1	range_score2
School			
S_1	65.5	97.0	33.5
S_2	62.8	95.5	39.4
```

```python
# 补充代码2
## 判断是否组内数学分数至少有一个值在50-52之间
# 返回s中是否存在low与high之间的数
> def f_test(s,low,high):
  	# max(): 有True则输出True
    return s.between(low,high).max()
> def agg_f(f_mul,name,*args,**kwargs):
    # 修饰器
    def wrapper(x):
        return f_mul(x,*args,**kwargs)
    wrapper.__name__ = name
    return wrapper
> new_f = agg_f(f_test,'at_least_one_in_50_52',50,52)
> grouped_single['Math'].agg([new_f,'mean']).head()
	at_least_one_in_50_52	mean
School		
S_1	False	63.746667
S_2	True	59.555000
```


```python
# 补充代码3
## 例1
> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
                           'foo', 'bar'],
                     'B' : [1, 2, 3, 4, 5, 6],
                     'C' : [2.0, 5., 8., 1., 2., 9.]})
> grouped = df.groupby('A')
> grouped.filter(lambda x: x['B'].mean() > 3.)
     A  B    C
1  bar  2  5.0
3  bar  4  1.0
5  bar  6  9.0

## 例2
### 将数学成绩大于32的组进行保留
> grouped_single[['Math','Physics']].filter(lambda x:(x['Math']>32).all()).head()
	Math	Physics
ID		
2101	83.3	C
2102	50.6	B+
2103	52.5	B-
2104	72.2	B+
2105	34.2	A
```



```python
# 补充代码4
> df.shape[0]
35
## 在特定范围内，随机取特定个整数
> np.random.randint(0,df.shape[0],25)
array([20, 31, 13,  6, 10, 14, 19, 24,  2,  8,  5,  5,  9, 22,  8,  0, 15,
        9,  2, 32, 26, 21, 19,  2, 12])
## 对Math列随机取NA
> df_nan = df[['Math','School']].copy().reset_index()
> df_nan.loc[np.random.randint(0,df.shape[0],25), ['Math']]=np.nan
> df_nan.head()
	ID	Math	School
0	1101	NaN	S_1
1	1102	32.5	S_1
2	1103	87.2	S_1
3	1104	NaN	S_1
4	1105	NaN	S_1
> df_nan.groupby('School').head(2)
	ID	Math	School
0	1101	NaN	S_1
1	1102	32.5	S_1
15	2101	NaN	S_2
16	2102	NaN	S_2
## 对分组后Math为NA的项用均值填充。对groupby对象转换后，会缺少分组列School，用join重新连接
> df_nan.groupby('School').transform(lambda x: x.fillna(x.mean())).join(df.reset_index()['School']).head()
	ID	Math	School
0	1101	61.977778	S_1
1	1102	32.500000	S_1
2	1103	87.200000	S_1
3	1104	61.977778	S_1
4	1105	61.977778	S_1
```



```python
# 补充代码5
> from collections import OrderedDict
> def f(df):
    data = OrderedDict()
    data['M_sum'] = df['Math'].sum()
    data['W_var'] = df['Weight'].var()
    data['H_mean'] = df['Height'].mean()
    return pd.Series(data)
> grouped_single.apply(f)
	M_sum	W_var	H_mean
School			
S_1	956.2	117.428571	175.733333
S_2	1191.1	181.081579	172.950000
```



## 二、参考资料和数据来源
### 1. 参考资料
1.  [Datawhale - Pandas教程 - 第三章](https://github.com/datawhalechina/joyful-pandas/blob/master/%E7%AC%AC3%E7%AB%A0%20%E5%88%86%E7%BB%84.ipynb)
2.  [Pandas官方文档（v3.8）](https://docs.python.org/3.8)
3. 《利用Python进行数据分析》第二版，Wes McKinney，机械工业出版社，2018年
 

### 2. 数据来源
本总结中部分数据和练习题的数据来源：
[Pandas教程，Datawhale](https://github.com/datawhalechina/joyful-pandas)

