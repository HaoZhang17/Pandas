# 第五章 合并

## 一、重难点总结

### 1. 数据合并方法总结

| 函数                        | 用途                                                         | 备注                                                         |
| --------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| `DataFrame.append()`        | 附加新<u>**行**</u>                                          |                                                              |
| `DataFrame.assign()`        | 附加新<u>**列**</u>                                          |                                                              |
| `DataFrame.concat()`        | <u>**轴向**</u>堆叠                                          | 可用`key`在连接轴向上创建多层索引以区分结果来源，连接后的索引可重复 |
| `DataFrame.merge()`         | 按键进行<u>**横向**</u>连接                                  | 默认将索引或重叠列名作为连接的键，也可分别指定（`on`）连接键；多对多连接结果为行的笛卡尔积；用`validate`检查两侧数据集中的连接键是否唯一；`indicator`指示合并后数据的来源 |
| `DataFrame.join()`          | 高效将多个对象按键进行<u>**横向**</u>连接                    | 默认将索引或重叠列名作为连接的键，也可分别指定（`on`）连接键；多对多连接结果为行的笛卡尔积 |
| `DataFrame.combine()`       | 用<u>**函数**</u>进行数据框之间的结合                        | 按照表的顺序逐列操作，自动索引对齐，缺失值为NaN；新数据框行、列索引是旧数据框行、列索引的并集 |
| `DataFrame.combine_first()` | 用于无效（Null）值、缺失值（NaN）的填充：使用来自其它数据框的非无效值填充原数据框中相同位置的无效值或缺失值 |                                                              |
| `DataFrame.update()`        | 用来自另一数据框的非缺失值按索引原位修改现有数据框           |                                                              |



### 2. `combine`方法注意事项

#### 1. 用函数进行数据框连接

```python
# 根据均值大小填充
> df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
> df2 = pd.DataFrame({'A': [8, 7], 'B': [6, 5]})
> df1.combine(df2,lambda x,y:x if x.mean()>y.mean() else y)
	A	B
0	8	6
1	7	5

# 根据加和最小填充
> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})
> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
> df1.combine(df2, lambda s1, s2: s1 if s1.sum() < s2.sum() else s2)
   A  B
0  0  3
1  0  3

# 使用真值结合函数
> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})
> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
> df1.combine(df2, np.minimum)
   A  B
0  1  2
1  0  3
```



#### 2. `fill_value`的使用

##### (1) 两个数据框相同位置中一方含有缺失值

先填充缺失值，再运用函数生成新数据框

```python
> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})
> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
> df1.combine(df2, lambda s1, s2: s1 if s1.sum() < s2.sum() else s2, fill_value=-5)
   A    B
0  0 -5.0
1  0  4.0
```
##### (2) 两个数据框相同位置均有缺失值
先保留None，运用函数生成新数据框，再在生成的数据框存在缺失值的位置填充

```python
> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})
> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})
> df1.combine(df2, lambda s1, s2: s1 if s1.sum() < s2.sum() else s2, fill_value=-5)
    A    B
0  0 -5.0
1  0  3.0
```
##### (3) 两数据框索引无法完全对齐
先运用函数生成新数据框，在生成的数据框存在缺失值的位置填充-1

```python
> df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
> df2 = pd.DataFrame({'B': [8, 7], 'C': [6, 5]},index=[1,2])
> df1.combine(df2, lambda x,y:x if x.mean()>y.mean() else y, fill_value=-1)
	A	B	C
0	1.0	-1.0	-1.0
1	2.0	8.0	6.0
2	-1.0	7.0	5.0
```
##### (4) 两个数据框相同位置中一方含有无效值，且两数据框索引无法完全对齐
先填充缺失值，再运用函数生成新数据框

```python
> df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
> df2 = pd.DataFrame({'B': [None, 7], 'C': [6, 5]},index=[1,2])
> df1.combine(df2, lambda x,y:x if x.mean()>y.mean() else y, fill_value=3, overwrite=False)
	A	B	C
0	1.0	3.0	3.0
1	2.0	3.0	6.0
2	NaN	7.0	5.0
```

#### 3. `overwrite`的使用 

If True, columns in self that do not exist in other will be overwritten with NaNs.

```python
# 例1
> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})
> df1
	A	B
0	0	NaN
1	0	4.0

> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])
> df2
	B	C
1	3	1
2	3	1

> df2.combine(df1, lambda s1, s2: s1 if s1.sum() < s2.sum() else s2)
	A	B	C
0  0.0  NaN NaN
1  0.0  3.0 NaN
2  NaN  3.0 NaN

## df1原来符合条件的值不会被覆盖
> df2.combine(df1, lambda s1, s2: s1 if s1.sum() < s2.sum() else s2, overwrite=False)
	A	B	C
0  0.0  NaN NaN
1  0.0  3.0 1.0
2  NaN  3.0 1.0

# 例2
## 如果不考虑覆盖，则A列依然存在缺失值
> df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
> df2 = pd.DataFrame({'B': [None, 7], 'C': [6, 5]},index=[1,2])
> df1.combine(df2, lambda x,y:x if x.mean()>y.mean() else y, fill_value=3, overwrite=False)
	A	B	C
0	1.0	3.0	3.0
1	2.0	3.0	6.0
2	NaN	7.0	5.0

## 在A列变为NaN后用3填充 
> df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
> df2 = pd.DataFrame({'B': [None, 7], 'C': [6, 5]},index=[1,2])
> df1.combine(df2, lambda x,y:x if x.mean()>y.mean() else y, fill_value=3, overwrite=True)
	A	B	C
0	3.0	3.0	3.0
1	3.0	3.0	6.0
2	3.0	7.0	5.0
```



## 二、问题与练习

### 1. 问题

#### 【问题一】 请思考什么是append/assign/combine/update/concat/merge/join各自最适合使用的场景，并举出相应的例子。

答：见上表“1. 数据合并方法总结”。

#### 【问题二】 merge_ordered和merge_asof的作用是什么？和merge是什么关系？

答：

`merge_order`: 按照键的顺序进行有顺序地填充、插入，适用于包含特定顺序的数据如时序数据。

`merge_asof`: 执行近似索引合并，类似于`merge`的左连接但匹配最近而非相等的键，可用于需要进行近似键合并的场景，如对于时序数据，可将时间作为合并的键进行相近时间的条目的合并。

这两个函数作为`merge`函数的补充，扩充了`merge`本身的功能，如对于要求键相等的合并，可选用`merge`函数；对于要进行近似键的合并，可选用`merge_asof`函数；对于需要按键的顺序进行时序数据的插入合并，可选用`merge_ordered`函数。

#### 【问题三】 请构造一个多级索引与多级索引合并的例子，尝试使用不同的合并函数。

答：后续有空再构造。

#### 【问题四】 上文提到了连接的笛卡尔积，那么当连接方式变化时（inner/outer/left/right），这种笛卡尔积规则会相应变化吗？请构造相应例子。

答：会发生相应变化，这里以`merge`函数进行举例：

```python
# 源数据
> df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'], 'data1': range(6)})
> df2 = pd.DataFrame({'key': ['a', 'b', 'a', 'b', 'd'], 'data2': range(5)})
> display(df1)
> display(df2)
	key	data1
0	b	0
1	b	1
2	a	2
3	c	3
4	a	4
5	b	5
	key	data2
0	a	0
1	b	1
2	a	2
3	b	3
4	d	4

# 左连接
## df1中存在但df2中不存在的键，在df2中被赋为缺失值
> pd.merge(df1, df2, on='key', how='left')
	key	data1	data2
0	b	0	1.0
1	b	0	3.0
2	b	1	1.0
3	b	1	3.0
4	a	2	0.0
5	a	2	2.0
6	c	3	NaN
7	a	4	0.0
8	a	4	2.0
9	b	5	1.0
10	b	5	3.0

# 右连接
## df2中存在但df1中不存在的键，在df1中被赋为缺失值
> pd.merge(df1, df2, on='key', how='right')
	key	data1	data2
0	b	0.0	1
1	b	1.0	1
2	b	5.0	1
3	b	0.0	3
4	b	1.0	3
5	b	5.0	3
6	a	2.0	0
7	a	4.0	0
8	a	2.0	2
9	a	4.0	2
10	d	NaN	4

# 内连接
## 仅用df1和df2的共有键进行合并
> pd.merge(df1, df2, on='key', how='inner')
	key	data1	data2
0	b	0	1
1	b	0	3
2	b	1	1
3	b	1	3
4	b	5	1
5	b	5	3
6	a	2	0
7	a	2	2
8	a	4	0
9	a	4	2

# 外连接
## 用df1和df2的所有键进行合并
> pd.merge(df1, df2, on='key', how='outer')
	key	data1	data2
0	b	0.0	1.0
1	b	0.0	3.0
2	b	1.0	1.0
3	b	1.0	3.0
4	b	5.0	1.0
5	b	5.0	3.0
6	a	2.0	0.0
7	a	2.0	2.0
8	a	4.0	0.0
9	a	4.0	2.0
10	c	3.0	NaN
11	d	NaN	4.0
```



### 2. 练习

#### 【练习一】有2张公司的员工信息表，每个公司共有16名员工，共有五个公司，请解决如下问题：
##### (a) 每个公司有多少员工满足如下条件：既出现第一张表，又出现在第二张表。

```python
> c1 = pd.read_csv('data/Employee1.csv')
> c1.head()
	Company	Name	Age	Height	Weight	Salary
0	A	a1	47	188	63.7	25819
1	A	a3	39	172	55.9	21983
2	A	a4	43	158	62.5	21755
3	A	a6	42	182	76.9	17354
4	A	a7	49	171	94.6	6177

> c2 = pd.read_csv('data/Employee2.csv')
> c2.head()
	Company	Name	Age	Height	Weight	Salary
0	A	a1	30	156	91.2	28133
1	A	a2	50	190	83.4	6673
2	A	a3	34	168	96.6	16503
3	A	a5	51	176	97.2	23294
4	A	a6	37	183	93.2	19256

# 方法一
> a = pd.merge(c1, c2, on='Name', how='inner')
> a.shape[0]
16

# 方法二
> c1_index.intersection(c2_index).size
16
```

##### (b) 将所有不符合(a)中条件的行筛选出来，合并为一张新表，列名与原表一致。

```python
> c1_index = pd.Index(c1['Name'])
> c2_index = pd.Index(c2['Name'])
> b_index = c1_index.union(c2_index).difference(c1_index.intersection(c2_index))
> a_index = c1_index.intersection(c2_index)
> combined = c1.append(c2, ignore_index=True)
> new_df = combined.loc[combined['Name'].isin(b_index), :].reset_index(drop=True)
> new_df.head()
	Company	Name	Age	Height	Weight	Salary
0	A	a4	43	158	62.5	21755
1	A	a7	49	171	94.6	6177
2	A	a8	51	168	89.5	3246
3	A	a9	36	186	62.8	3569
4	A	a13	58	190	75.9	21854
```

##### (c) 现在需要编制所有80位员工的信息表，对于(b)中的员工要求不变，对于满足(a)条件员工，它们在某个指标的数值，取偏离它所属公司中满足(b)员工的均值数较小的哪一个，例如：P公司在两张表的交集为{p1}，并集扣除交集为{p2,p3,p4}，那么如果后者集合的工资均值为1万元，且p1在表1的工资为13000元，在表2的工资为9000元，那么应该最后取9000元作为p1的工资，最后对于没有信息的员工，利用缺失值填充。

```python
> take_smaller = lambda s1, s2: s1 if s1.mean() < s2.mean() else s2

# age
> c1_age = c1.loc[c1['Name'].isin(a['Name']), :][['Name', 'Age']].set_index('Name', drop=True).T
> c2_age = c2.loc[c2['Name'].isin(a['Name']), :][['Name', 'Age']].set_index('Name', drop=True).T
> a_age = c1_age.combine(c2_age, take_smaller).T.reset_index()

# height
> c1_height = c1.loc[c1['Name'].isin(a['Name']), :][['Name', 'Height']].set_index('Name', drop=True).T
> c2_height = c2.loc[c2['Name'].isin(a['Name']), :][['Name', 'Height']].set_index('Name', drop=True).T
> a_height = c1_height.combine(c2_height, take_smaller).T.reset_index()

# weight
> c1_weight = c1.loc[c1['Name'].isin(a['Name']), :][['Name', 'Weight']].set_index('Name', drop=True).T
> c2_weight = c2.loc[c2['Name'].isin(a['Name']), :][['Name', 'Weight']].set_index('Name', drop=True).T
> a_weight = c1_weight.combine(c2_weight, take_smaller).T.reset_index()

# salary
> c1_sal = c1.loc[c1['Name'].isin(a['Name']), :][['Name', 'Salary']].set_index('Name', drop=True).T
> c2_sal = c2.loc[c2['Name'].isin(a['Name']), :][['Name', 'Salary']].set_index('Name', drop=True).T
> a_sal = c1_sal.combine(c2_sal, take_smaller).T.reset_index()

> a_info = combined[['Company', 'Name']].loc[combined['Name'].isin(a['Name']), :].drop_duplicates()
> a_combined = a_info.merge(a_age, on='Name').merge(a_height, on='Name').merge(a_weight, on='Name').merge(a_sal, on='Name')

# combine with b
> ab_combined = a_combined.append(new_df)

# employees without info
> all_info = pd.DataFrame({'Company': [x for x in ['A', 'B', 'C', 'D', 'E'] for i in range(16)], 'Name':[x+str(y) for x in ['a', 'b', 'c', 'd', 'e'] for y in range(1, 17)]})
> all_index = pd.Index(all_info['Name'])
> noinfo_index = all_index.difference(c1_index).difference(c2_index)

> all_info.loc[all_info['Name'].isin(noinfo_index),:].merge(ab_combined, on=['Company', 'Name'], how='outer').sort_values(by=['Company', 'Name']).reset_index(drop=True)
	Company	Name	Age	Height	Weight	Salary
0	A	a1	30.0	156.0	63.7	25819.0
1	A	a10	56.0	164.0	82.2	24799.0
2	A	a11	NaN	NaN	NaN	NaN
3	A	a12	36.0	177.0	96.9	10270.0
4	A	a13	58.0	190.0	75.9	21854.0
...	...	...	...	...	...	...
75	E	e5	NaN	NaN	NaN	NaN
76	E	e6	44.0	165.0	91.5	28818.0
77	E	e7	44.0	164.0	51.9	13035.0
78	E	e8	45.0	171.0	68.1	15832.0
79	E	e9	NaN	NaN	NaN	NaN
80 rows × 6 columns
```

#### 【练习二】有2张课程的分数表（分数随机生成），但专业课（学科基础课、专业必修课、专业选修课）与其他课程混在一起，请解决如下问题：

##### (a) 将两张表分别拆分为专业课与非专业课（结果为四张表）

```python
> s1 = pd.read_csv('data/Course1.csv')
> s1.head()
	课程名字	课程类别	学分	分数
0	思想道德修养与法律基础	思政类	3	89.0
1	云计算应用与开发	专业选修课	3	96.0
2	社会计算	专业选修课	3	78.0
3	深度学习	专业选修课	3	75.0
4	人工智能导论	专业必修课	3	84.0

> s2 = pd.read_csv('data/Course2.csv')
> s2.head()
	课程名字	课程类别	学分	分数
0	高等数学（一）	学科基础课	4	99.0
1	数据科学与工程导论	学科基础课	3	NaN
2	专业英语	学科基础课	2	100.0
3	概率论	学科基础课	3	99.0
4	计算机系统	专业必修课	4	80.0

# 构造选择课程类别的函数
> sc = lambda x: x.startswith('专业')

# 表1
## 专业课
> sc_1 = s1.loc[s1['课程类别'].apply(sc), :]
## 非专业课
> nc_1 = s1.loc[~s1['课程类别'].apply(sc), :]

# 表2
## 专业课
> sc_2 = s2.loc[s2['课程类别'].apply(sc), :]
## 非专业课
> nc_2 = s2.loc[~s2['课程类别'].apply(sc), :]
```

##### (b) 将两张专业课的分数表和两张非专业课的分数表分别合并

```python
> sc_all = sc_1.append(sc_2).reset_index(drop=True)
> nc_all = nc_1.append(nc_2).reset_index(drop=True)
```

##### (c) 不使用(a)中的步骤，请直接读取两张表合并后拆分

```python
> all = pd.concat([s1, s2], axis=0, keys=['s1', 's2'])
> all.loc['s1', :].loc[s1['课程类别'].apply(sc), :]

# 表1
## 专业课
> sc_1 = all.loc['s1', :].loc[s1['课程类别'].apply(sc), :]
## 非专业课
> nc_1 = all.loc['s1', :].loc[~s1['课程类别'].apply(sc), :]

# 表2
## 专业课
> sc_2 = all.loc['s2', :].loc[s2['课程类别'].apply(sc), :]
## 非专业课
> nc_2 = all.loc['s2', :].loc[~s2['课程类别'].apply(sc), :]
```

##### (d) 专业课程中有缺失值吗，如果有的话请在完成(3)的同时，用组内（3种类型的专业课）均值填充缺失值后拆分

```python
# 查看两个表中缺失的数据
> s1.loc[(s1['分数'].isna()),:]
	课程名字	课程类别	学分	分数
14	计算机视觉	专业选修课	3	NaN

> s2.loc[(s2['分数'].isna()),:]
	课程名字	课程类别	学分	分数
1	数据科学与工程导论	学科基础课	3	NaN
11	数据伦理	专业必修课	1	NaN

# 定义填充函数
def f(s):
    s['分数'][s['分数'].isna()] = s['分数'][~s['分数'].isna()].mean()
    return s

# 表1-专业课
sc_1_new = sc_1.groupby('课程类别').apply(f)
# 表1-非专业课
nc_1_new = nc_1.groupby('课程类别').apply(f)
# 表2-专业课
sc_2_new = sc_2.groupby('课程类别').apply(f)
# 表2-非专业课
nc_2_new = nc_2.groupby('课程类别').apply(f)
```

## 三、参考资料和数据来源

### 1. 参考资料

1.  [Datawhale - Pandas教程 - 第五章](https://github.com/datawhalechina/joyful-pandas/blob/master/%E7%AC%AC5%E7%AB%A0%20%E5%90%88%E5%B9%B6.ipynb)
2.  [Pandas官方文档（v1.0.3）](https://pandas.pydata.org/docs/user_guide/)
3. 《利用Python进行数据分析》第二版，Wes McKinney，机械工业出版社，2018年

### 2. 数据来源
本总结中部分数据和练习题的数据来源：
[Pandas教程及附带数据，Datawhale](https://github.com/datawhalechina/joyful-pandas)
