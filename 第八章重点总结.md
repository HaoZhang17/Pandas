# 第八章 分类数据

## 一、重难点总结

### 1. 分类变量的创建

| 方式                          | 举例                                                         |
| ----------------------------- | ------------------------------------------------------------ |
| 基于`Series`创建              | `pd.Series(["a", "b", "c", "a"], dtype="category")`          |
| 基于`DataFrame`创建           | `pd.DataFrame({'A':pd.Series(["a", "b", "c", "a"], dtype="category"),'B':list('abcd')})` |
| 利用内置`Categorical`类型创建 | `pd.Categorical(["a", "b", "c", "a"], categories=['a','b','c'])` |
| 利用`cut`函数创建             | `pd.cut(np.random.randint(0,60,5), [0,10,30,60], right=False, labels=['0-10','10-30','30-60'])` |

### 2. 分类变量的排序

#### 1) 使用`as_order`将序列转为有序变量

```python
> s = pd.Series(["a", "d", "c", "a"]).astype('category').cat.as_ordered()
> s
0    a
1    d
2    c
3    a
dtype: category
Categories (3, object): [a < c < d]
```

#### 2) 使用`as_unorder`将有序变量转为无序变量

```python
> s.cat.as_unordered()
0    a
1    d
2    c
3    a
dtype: category
Categories (3, object): [a, c, d]
```

#### 3) 利用`set_categories`方法中的`order`参数

`set_categories`允许设置的分类与原分类不同

```python
> pd.Series(["a", "d", "c", "a"]).astype('category').cat.set_categories(['a','d','c','e'],ordered=True)
0    a
1    d
2    c
3    a
dtype: category
Categories (4, object): [a < d < c < e]
```

#### 4) `reorder_categories`方法

`reorder_categories`要求新设置的分类必须与原分类为同一集合

```python
> s = pd.Series(["a", "d", "c", "a"]).astype('category')
> s.cat.reorder_categories(['a','d','c'],ordered=True)
0    a
1    d
2    c
3    a
dtype: category
Categories (3, object): [a < d < c]

#s.cat.reorder_categories(['a','c'],ordered=True) #报错
#s.cat.reorder_categories(['a','c','d','e'],ordered=True) #报错
```



## 二、问题与练习

### 1. 问题
#### 【问题一】 如何使用union_categoricals方法？它的作用是什么？

合并分类变量，要求所有的`Category`必须有相同的`dtype`，支持`Categorical`、`CategoricalIndex`或`dtype`为`category`的`Series`。其有两个重要参数：

* `sort_categories`：是否将类别进行排序
* `ignore_order`：是否忽略原有的类别排序

```python
> from pandas.api.types import union_categoricals
> a = pd.Categorical(["b", "c"])
> b = pd.Categorical(["a", "b"])

> union_categoricals([a, b])
[b, c, a, b]
Categories (3, object): [b, c, a]
  
> union_categoricals([a, b], sort_categories=True)
[b, c, a, b]
Categories (3, object): [a, b, c]

> a = pd.Categorical(["a", "b"], ordered=True)
> b = pd.Categorical(["a", "b", "a"], ordered=True)

> union_categoricals([a, b])
[a, b, a, b, a]
Categories (2, object): [a < b]

> a = pd.Categorical(["a", "b", "c"], ordered=True)
> b = pd.Categorical(["c", "b", "a"], ordered=True)

> union_categoricals([a, b], ignore_order=True)
[a, b, c, c, b, a]
Categories (3, object): [a, b, c]

> union_categoricals([a, b])
[a, b, c, c, b, a]
Categories (3, object): [a < b < c]
```



#### 【问题二】 利用concat方法将两个序列纵向拼接，它的结果一定是分类变量吗？什么情况下不是？

```python
# 没太懂问题
> s1 = pd.Series(['a', 'b']).astype('category')
> s2 = pd.Series(['c', 'd']).astype('category')
> pd.concat([s1, s2], axis = 0)
0    a
1    b
0    c
1    d
dtype: object
```



#### 【问题三】 当使用groupby方法或者value_counts方法时，分类变量的统计结果和普通变量有什么区别？

普通变量：针对原有变量进行操作

分类变量：针对分箱后的数值或类别进行统计，索引为分箱值或类别名，`value_counts`实际无效

```python
> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon', 'Falcon', 'Falcon','Parrot', 'Parrot', 'Parrot', 'Parrot'], 'Max Speed': [100, 70, 80, 90, 70, 60, 50, 60]})

> df.groupby('Animal').mean()
	Max Speed
Animal	
Falcon	85
Parrot	60

> df['Animal'].value_counts()
Parrot    4
Falcon    4
Name: Animal, dtype: int64

# 数值型类别变量
> a = np.random.randint(0,60,8)
> a
array([ 9,  9, 42, 52, 19,  6, 35, 31])
> df['Height'] = pd.cut(a, [0,10,30,60], right=False)

> df['Height'].value_counts
<bound method IndexOpsMixin.value_counts of 
0     [0, 10)
1     [0, 10)
2    [30, 60)
3    [30, 60)
4    [10, 30)
5     [0, 10)
6    [30, 60)
7    [30, 60)
Name: Height, dtype: category
Categories (3, interval[int64]): [[0, 10) < [10, 30) < [30, 60)]>

> df.groupby('Height').mean()
	Max Speed
Height	
[0, 10)	76.666667
[10, 30)	70.000000
[30, 60)	70.000000

# 非数值型类别变量
> df['Type'] = pd.Series(pd.Categorical(["a", "b", "c", "a", "d", "b", "a", "c"], categories=['a','b','c','d']))
> df
	Animal	Max Speed	Height	Type
0	Falcon	100	[0, 10)	a
1	Falcon	70	[0, 10)	b
2	Falcon	80	[30, 60)	c
3	Falcon	90	[30, 60)	a
4	Parrot	70	[10, 30)	d
5	Parrot	60	[0, 10)	b
6	Parrot	50	[30, 60)	a
7	Parrot	60	[30, 60)	c
               
> df.groupby('Type').mean()
 Max Speed
Type	
a	80
b	65
c	70
d	70
```



#### 【问题四】 下面的代码说明了Series创建分类变量的什么“缺陷”？如何避免？（提示：使用Series中的copy参数）

```python
> cat = pd.Categorical([1, 2, 3, 10], categories=[1, 2, 3, 4, 10])
> s = pd.Series(cat, name="cat")
> cat
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

> s.iloc[0:2] = 10
> cat
[10, 10, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]
```

使用分类变量创建`Series`会使`Series`的数据和原始分类变量的数据指向同一内存地址。如果对`Series`的数据进行修改，分类变量数据也会相应修改。可在修改前对`Series`使用`copy`方法进行复制。



### 2. 练习

#### 【练习一】 现继续使用第四章中的地震数据集，请解决以下问题：
#### （a）现在将深度分为七个等级：[0,5,10,15,20,30,50,np.inf]，请以深度等级Ⅰ,Ⅱ,Ⅲ,Ⅳ,Ⅴ,Ⅵ,Ⅶ为索引并按照由浅到深的顺序进行排序

```python
> ex1 = pd.read_csv('data/Earthquake.csv')
> ex1.head()
	日期	时间	维度	经度	方向	距离	深度	烈度
0	2003.05.20	12:17:44 AM	39.04	40.38	west	0.1	10.0	0.0
1	2007.08.01	12:03:08 AM	40.79	30.09	west	0.1	5.2	4.0
2	1978.05.07	12:41:37 AM	38.58	27.61	south_west	0.1	0.0	0.0
3	1997.03.22	12:31:45 AM	39.47	36.44	south_west	0.1	10.0	0.0
4	2000.04.02	12:57:38 AM	40.80	30.24	south_west	0.1	7.0	0.0

> a = pd.cut(ex1['深度'], [0,5,10,15,20,30,50,np.inf], right = False, labels=['I','II','III', 'IV', 'V', 'VI', 'VII'])
> ex1_1 = ex1.loc[:,~ex1.columns.isin(['深度'])]
> ex1_2 = pd.concat([ex1_1, a], axis =1).reset_index(drop=True).set_index('深度').sort_index()
> ex1_2.head()
	日期	时间	维度	经度	方向	距离	烈度
深度							
I	1999.07.05	12:57:31 AM	41.24	32.78	north_west	0.9	0.0
I	1994.12.24	12:40:49 AM	37.48	28.35	north_east	1.0	0.0
I	2001.12.12	12:59:55 AM	37.42	37.28	north_east	3.2	0.0
I	2017.04.21	12:25:56 AM	38.78	29.06	south_east	1.5	3.8
I	1992.08.21	12:10:52 AM	37.61	27.48	north_east	1.0	0.0
```



#### （b）在（a）的基础上，将烈度分为4个等级：[0,3,4,5,np.inf]，依次对南部地区的深度和烈度等级建立多级索引排序

```python
> b = pd.cut(ex1_2['烈度'], [0,3,4,5,np.inf], right=False)
> ex1_3 = ex1_2.loc[:,~ex1_2.columns.isin(['烈度'])]
> ex1_4 = pd.concat([ex1_3, b], axis =1)
> ex1_4.loc[ex1_4['方向'] == 'south',:].reset_index().set_index(['深度','烈度'])
		日期	时间	维度	经度	方向	距离
深度	烈度						
I	[0.0, 3.0)	1977.04.20	12:26:53 AM	38.94	27.20	south	1.5
[0.0, 3.0)	1990.09.27	12:45:12 AM	37.87	27.47	south	1.5
[0.0, 3.0)	1999.06.18	12:46:37 AM	40.92	33.92	south	1.0
[3.0, 4.0)	2011.10.23	12:46:11 AM	38.75	43.25	south	1.5
[0.0, 3.0)	1999.02.10	12:47:57 AM	39.93	40.42	south	1.0
...	...	...	...	...	...	...	...
VII	[0.0, 3.0)	1973.03.02	12:30:01 AM	39.20	28.10	south	0.7
[0.0, 3.0)	1976.02.14	12:14:00 AM	37.70	29.00	south	7.4
[4.0, 5.0)	1964.11.20	12:59:19 AM	40.20	28.06	south	3.6
[0.0, 3.0)	1980.12.02	12:31:52 AM	36.91	28.63	south	4.5
[4.0, 5.0)	1968.03.21	12:42:51 AM	38.80	27.60	south	0.6
605 rows × 6 columns
```



#### 【练习二】 对于分类变量而言，调用第4章中的变形函数会出现一个BUG（目前的版本下还未修复）：例如对于crosstab函数，按照[官方文档的说法](https://pandas.pydata.org/pandas-docs/version/1.0.0/user_guide/reshaping.html#cross-tabulations)，即使没有出现的变量也会在变形后的汇总结果中出现，但事实上并不是这样，比如下面的例子就缺少了原本应该出现的行'c'和列'f'。基于这一问题，请尝试设计my_crosstab函数，在功能上能够返回正确的结果。

```python
> foo = pd.Categorical(['a', 'b'], categories=['a', 'b', 'c', 'g'])
> bar = pd.Categorical(['d', 'e'], categories=['d', 'e', 'f', 'h'])

> def my_crosstab(x,y):
      a = pd.crosstab(x, y)

      # CategoryIndex不能直接用concat连接，否则报错
      a.index = a.index.astype('str')
      a.columns = a.columns.astype('str')

      for c_x in x.categories:
          if c_x not in x:
              a = pd.concat([a, pd.Series(a.shape[0] * [0], name=c_x, index=a.index)], axis=1)
      for c_y in y.categories:
          if c_y not in y:
              b = pd.Series(a.shape[1] * [0], name=c_y, index=a.columns)
              a = a.append(b)
      return a

> my_crosstab(foo, bar)
	d	e	c	g
row_0				
a	1	0	0	0
b	0	1	0	0
f	0	0	0	0
h	0	0	0	0
```



## 三、参考资料和数据来源

### 1. 参考资料

1.  [Datawhale - Pandas教程 - 第八章](https://github.com/datawhalechina/joyful-pandas/blob/master/%E7%AC%AC8%E7%AB%A0%20%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE.ipynb)
2.  [Pandas官方文档](https://pandas.pydata.org/docs/user_guide/)
3. 《利用Python进行数据分析》第二版，Wes McKinney，机械工业出版社，2018年

### 2. 数据来源
本总结中部分数据和练习题的数据来源：
[Pandas教程及附带数据，Datawhale](https://github.com/datawhalechina/joyful-pandas)
